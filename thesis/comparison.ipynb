{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d611cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from src.config.core import Config\n",
    "import src.dataset as ds\n",
    "import src.training.utils as train_utils\n",
    "import src.inference.utils as inf_utils\n",
    "from src.inference.evaluation import evaluate_bde\n",
    "from src.types import ParamTree\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad23108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(path, type, ms, seeds, exploration_steps, schedule='constant'):\n",
    "    df = pd.DataFrame(columns=['m', 'lppd', 'rmse', 'time', 'seed'])\n",
    "    nan_counts = []\n",
    "    for i, m in enumerate(ms):\n",
    "        nan_count = 0\n",
    "        for seed in seeds:\n",
    "            if type == 'parallel':\n",
    "                results_dir = f'{path}/{m}x1_{schedule}_{exploration_steps}+500_seed{seed+i}'\n",
    "            else:\n",
    "                results_dir = f'{path}/1x{m}_{schedule}_{exploration_steps}+500_seed{seed+i}'\n",
    "\n",
    "            metrics_dir = f'{results_dir}/eval_metrics.pkl'\n",
    "            samples_dir = f'{results_dir}/samples'\n",
    "            tree_path = f'{results_dir}/tree'\n",
    "            if not os.path.exists(metrics_dir):\n",
    "                nan_count += 1\n",
    "                print(f'Skipping {results_dir} - does not exist')\n",
    "                samples = train_utils.load_samples_from_dir(samples_dir, tree_path=tree_path)\n",
    "                samples_nan = jax.tree.map(lambda x: jnp.isnan(x), samples)\n",
    "                print(f'Found NaN in samples: {samples_nan}')\n",
    "                break\n",
    "            with open(f'{results_dir}/eval_metrics.pkl', 'rb') as f:\n",
    "                eval_metrics = pickle.load(f)\n",
    "            with open(f'{results_dir}/samples/info.pkl', 'rb') as f:\n",
    "                info = pickle.load(f)\n",
    "            curr_lppd = eval_metrics['lppd']\n",
    "            curr_rmse = eval_metrics['rmse']\n",
    "            # lppd.append(curr_lppd)\n",
    "            # rmse.append(curr_rmse)\n",
    "            # times.append(info['total_time'])\n",
    "            df = pd.concat([df, pd.DataFrame({\n",
    "                'm': [m],\n",
    "                'lppd': [curr_lppd],\n",
    "                'rmse': [curr_rmse],\n",
    "                'time': [info['total_time']],\n",
    "                'seed': [seed+i]\n",
    "            })], ignore_index=True)\n",
    "        nan_counts.append(nan_count)\n",
    "\n",
    "    print(f'Nan counts: {nan_counts}')\n",
    "\n",
    "    df = df.groupby('m').agg({\n",
    "        'lppd': ['mean', 'std'],\n",
    "        'rmse': ['mean', 'std'],\n",
    "        'time': ['mean', 'std'],\n",
    "        # 'seed': 'count'\n",
    "    }).reset_index().rename(columns={'index': 'm'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a86806",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms=np.array([2, 4, 6, 8, 10, 12])\n",
    "seeds = [0, 42, 221, 476, 1453, 1644, 1840, 1973, 2025, 2100]\n",
    "# seeds = [0, 42, 1973, 2025, 2100]\n",
    "res_parallel_5k = load_results('results/constant', 'parallel', ms=ms, seeds=seeds, exploration_steps=5000)\n",
    "res_parallel_2k = load_results('results/constant', 'parallel', ms=ms, seeds=seeds, exploration_steps=2000)\n",
    "res_sequential_2k = load_results('results/constant', 'sequential', ms=ms, seeds=seeds, exploration_steps=2000)\n",
    "res_sequential_5k = load_results('results/constant', 'sequential', ms=ms, seeds=seeds, exploration_steps=5000)\n",
    "res_parallel_2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecba313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(res_parallel, res_sequential):\n",
    "    ms = res_parallel['m'].to_numpy()\n",
    "    mean_lppd_parallel = res_parallel['lppd']['mean'].to_numpy()\n",
    "    std_lppd_parallel = res_parallel['lppd']['std'].to_numpy()\n",
    "    mean_rmse_parallel = res_parallel['rmse']['mean'].to_numpy()\n",
    "    std_rmse_parallel = res_parallel['rmse']['std'].to_numpy()\n",
    "\n",
    "    mean_lppd_sequential = res_sequential['lppd']['mean'].to_numpy()\n",
    "    std_lppd_sequential = res_sequential['lppd']['std'].to_numpy()\n",
    "    mean_rmse_sequential = res_sequential['rmse']['mean'].to_numpy()\n",
    "    std_rmse_sequential = res_sequential['rmse']['std'].to_numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(6.3, 6.3/2), ncols=2)\n",
    "    axs[0].errorbar(ms+0.1, mean_lppd_parallel, yerr=std_lppd_parallel, fmt='s--', label='parallel', color='blue')\n",
    "    axs[0].errorbar(ms-0.1, mean_lppd_sequential, yerr=std_lppd_sequential, fmt='s--', label='sequential', color='red')\n",
    "    axs[0].set_ylabel('LPPD')\n",
    "    axs[0].set_xlabel('Number of chains/cycles')\n",
    "    axs[1].errorbar(ms+0.1, mean_rmse_parallel, yerr=std_rmse_parallel, fmt='s--', label='parallel', color='blue')\n",
    "    axs[1].errorbar(ms-0.1, mean_rmse_sequential, yerr=std_rmse_sequential, fmt='s--', label='sequential', color='red')\n",
    "    axs[1].set_ylabel('RMSE')\n",
    "    axs[1].set_xlabel('Number of chains/cycles')\n",
    "\n",
    "    axs[0].set_xticks(ms)\n",
    "    axs[0].set_xticklabels(ms)\n",
    "    axs[1].set_xticks(ms)\n",
    "    axs[1].set_xticklabels(ms)\n",
    "\n",
    "    # Remove duplicate labels in the legend\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    fig.legend(by_label.values(), by_label.keys(), loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_comparison(res_parallel_2k, res_sequential_2k)\n",
    "# plt.savefig('../ba/images/parallel_vs_sequential_constant_2k.pdf', bbox_inches='tight')\n",
    "\n",
    "fig, axs = plot_comparison(res_parallel_5k, res_sequential_5k)\n",
    "# plt.savefig('../ba/images/parallel_vs_sequential_constant_5k.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e78f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_parallel_2k['lppd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04526238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_mean_std(res):\n",
    "    combined = res.copy()\n",
    "    combined.columns = combined.columns.map(\"_\".join)\n",
    "    for col in ['lppd', 'rmse', 'time']:\n",
    "        for suffix in ['mean', 'std']:\n",
    "            name = f'{col}_{suffix}'\n",
    "            combined[name] = combined[name].astype(\"float64\").map(lambda x: f'{x:.3f}')\n",
    "        combined[col] = combined[f'{col}_mean'].astype(str) + r' $\\pm$ ' + combined[f'{col}_std'].astype(str)\n",
    "    return combined[[\"m_\", \"lppd\", \"rmse\", \"time\"]].rename(columns={'m_': 'm'})\n",
    "\n",
    "def full_performance_table(res_par, res_seq, fn=\"tmp.tex\"):\n",
    "    res_par = combine_mean_std(res_par)\n",
    "    res_seq = combine_mean_std(res_seq)\n",
    "    m = r'$M$'\n",
    "    lppd = r'LPPD ($\\uparrow$)'\n",
    "    rmse = r'RMSE ($\\downarrow$)'\n",
    "    header = pd.MultiIndex.from_tuples([\n",
    "        (m, ''),\n",
    "        (lppd, 'parallel'),\n",
    "        (lppd, 'sequential'),\n",
    "        (rmse, 'parallel'),\n",
    "        (rmse, 'sequential'),\n",
    "        # ('time', 'parallel'),\n",
    "        # ('time', 'sequential')\n",
    "    ])\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    df[(m, '')] = res_par['m']\n",
    "    df[(lppd, 'parallel')] = res_par['lppd']\n",
    "    df[(lppd, 'sequential')] = res_seq['lppd']\n",
    "    df[(rmse, 'parallel')] = res_par['rmse']\n",
    "    df[(rmse, 'sequential')] = res_seq['rmse']\n",
    "    with open(fn, 'w') as f:\n",
    "        df.to_latex(\n",
    "            f,\n",
    "            index=False,\n",
    "            column_format='c' * len(header),\n",
    "            escape=False,\n",
    "            multicolumn=True,\n",
    "            multicolumn_format='c',\n",
    "        )\n",
    "\n",
    "full_performance_table(res_parallel_2k, res_sequential_2k, fn=\"tmp_2k.tex\")\n",
    "full_performance_table(res_parallel_5k, res_sequential_5k, fn=\"tmp_5k.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ed782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more quantitative comparison\n",
    "df = pd.DataFrame({\n",
    "    r'$M$': res_parallel_2k['m'],\n",
    "    'LPPD (2k)': res_sequential_2k['lppd']['mean'] - res_parallel_2k['lppd']['mean'],\n",
    "    'LPPD (5k)': res_sequential_5k['lppd']['mean'] - res_parallel_5k['lppd']['mean'],\n",
    "    'RMSE (2k)': res_sequential_2k['rmse']['mean'] - res_parallel_2k['rmse']['mean'],\n",
    "    # '2k_runtime': res_sequential_2k['time']['mean'] - res_parallel_2k['time']['mean'],\n",
    "    'RMSE (5k)': res_sequential_5k['rmse']['mean'] - res_parallel_5k['rmse']['mean'],\n",
    "    # '5k_runtime': res_sequential_5k['time']['mean'] - res_parallel_5k['time']['mean']\n",
    "})\n",
    "summary = df.agg([\"mean\"])\n",
    "# \"average\" of m is meaningless\n",
    "print(df)\n",
    "df = pd.concat([df, summary])\n",
    "formatter = {\n",
    "    'LPPD (2k)': lambda x: f'{x:.3f}',\n",
    "    'LPPD (5k)': lambda x: f'{x:.3f}',\n",
    "    'RMSE (2k)': lambda x: f'{x:.3f}',\n",
    "    'RMSE (5k)': lambda x: f'{x:.3f}',\n",
    "    r'$M$': lambda x: f'{int(x)}' if x != 7 else 'Average',\n",
    "}\n",
    "df.to_latex(\"tmp_diff.tex\", index=False, formatters=formatter, column_format='rrrrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d137d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'm': res_parallel_5k['m'],\n",
    "    'mean_time_parallel': res_parallel_5k['time']['mean'],\n",
    "    'std_time_parallel': res_parallel_5k['time']['std'],\n",
    "    'mean_time_sequential': res_sequential_5k['time']['mean'],\n",
    "    'std_time_sequential': res_sequential_5k['time']['std']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ffffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime\n",
    "fig, ax = plt.subplots(figsize=(0.8*6.3, 0.8*6.3/3*2))\n",
    "# ax.plot(ms, res_parallel_5k['time']['mean'], 'o--', label='parallel', color='blue')\n",
    "# ax.plot(ms, res_sequential_5k['time']['mean'], 'o--', label='sequential', color='red')\n",
    "ax.errorbar(ms, res_parallel_5k['time']['mean'], yerr=np.asarray(res_parallel_5k['time']['std']), fmt='o--', label='parallel+constant', color='blue', markersize=3)\n",
    "ax.errorbar(ms, res_sequential_5k['time']['mean'], yerr=np.asarray(res_sequential_5k['time']['std']), fmt='o--', label='sequential+constant', color='red', markersize=3)\n",
    "ax.set_ylabel('Runtime [s]')\n",
    "ax.set_xlabel('Number of chains/cycles')\n",
    "plt.legend(loc='upper left')\n",
    "# plt.savefig('../ba/images/parallel_vs_sequential_constant_5k_runtime.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d3a71",
   "metadata": {},
   "source": [
    "### Exploration budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e675fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bde_from_file(\n",
    "    results_dir: Path,\n",
    "    samples: ParamTree | None = None,\n",
    "    cycle: int | None = None,\n",
    "    chain: int | None = None,\n",
    "    batch_size: int | None = None\n",
    "):\n",
    "    # \"\"\"Evaluate BDE from a file.\"\"\"\n",
    "    if samples is None:\n",
    "        sample_path = results_dir / 'samples'\n",
    "        tree_path = results_dir / 'tree'\n",
    "        samples = train_utils.load_samples_from_dir(sample_path, tree_path)\n",
    "\n",
    "    config = Config.from_yaml(results_dir / 'config.yaml')\n",
    "    n_samples = inf_utils.count_samples(samples)\n",
    "    n_cycles = config.training.sampler.scheduler_config.parameters['n_cycles']\n",
    "    n_chains = inf_utils.count_chains(samples)\n",
    "\n",
    "    n_samples_per_cycle = n_samples // n_cycles\n",
    "\n",
    "    if cycle is not None:\n",
    "        assert 0 <= cycle < n_cycles, f'Cycle index {cycle} must be between 0 and {n_cycles}-1'\n",
    "        samples = jax.tree.map(\n",
    "            lambda x: x[:, cycle * n_samples_per_cycle : (cycle+1) * n_samples_per_cycle],\n",
    "            samples\n",
    "        )\n",
    "    if chain is not None:\n",
    "        assert 0 <= chain < n_chains, f'Chain index {chain} must be between 0 and {n_chains}-1'\n",
    "        samples = jax.tree.map(\n",
    "            lambda x: x[chain, ...][None, ...], # always preserve the chain dimension\n",
    "            samples\n",
    "        )\n",
    "\n",
    "    # print(jax.tree.map(lambda x: x.shape, samples))\n",
    "\n",
    "    module = config.get_flax_model()\n",
    "    loader = ds.TabularLoader(\n",
    "        config.data,\n",
    "        rng=config.jax_rng,\n",
    "        target_len=config.data.target_len\n",
    "    )\n",
    "\n",
    "    features = loader.test_x # (B x F)\n",
    "    labels = loader.test_y # (B x T)\n",
    "\n",
    "    metrics = {}\n",
    "    logits, metrics = evaluate_bde(\n",
    "        params=samples, # type: ignore\n",
    "        module=module,\n",
    "        features=features,\n",
    "        labels=labels,\n",
    "        task=config.data.task,\n",
    "        batch_size=batch_size,\n",
    "        verbose=False,\n",
    "        metrics_dict=metrics,\n",
    "        nominal_coverages=[0.5, 0.75, 0.9, 0.95],\n",
    "        per_chain=False\n",
    "    )\n",
    "\n",
    "    return logits, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbb9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "dir = Path('results/exploration_budget')\n",
    "\n",
    "# os.listdir(results_dir)\n",
    "pattern = r'1x12_constant_(\\d+)\\+(\\d+)_10_seed(\\d+)'\n",
    "n_cycles = 12\n",
    "all_metrics = []\n",
    "# exploration_lengths = [2000, 3000, 4000, 5000, 6000]\n",
    "all_metrics = []\n",
    "for result in sorted(os.listdir(dir)):\n",
    "    match = re.match(pattern, result)\n",
    "    if not match:\n",
    "        continue\n",
    "    results_dir = dir / result\n",
    "    exploration_steps = int(match.group(1))\n",
    "    samples = train_utils.load_samples_from_dir(\n",
    "        results_dir / 'samples',\n",
    "        tree_path=results_dir / 'tree'\n",
    "    )\n",
    "    for cycle in range(n_cycles):\n",
    "        print(f'Evaluating cycle {cycle} in {results_dir}')\n",
    "        logits, metrics = evaluate_bde_from_file(\n",
    "            results_dir=results_dir,\n",
    "            samples=samples,\n",
    "            cycle=cycle,\n",
    "            chain=None,\n",
    "            batch_size=None\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "        all_metrics.append({\n",
    "            'cycle': cycle + 1,  # 1-indexed for plotting\n",
    "            'exploration_steps': exploration_steps,\n",
    "            'lppd': metrics['lppd'],\n",
    "            'rmse': metrics['rmse']\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27819119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(['exploration_steps', 'cycle']).agg({\n",
    "    'lppd': ['mean', 'std'],\n",
    "    'rmse': ['mean', 'std']\n",
    "})\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(6.3, 6.3/4*3), sharey='all')\n",
    "for i, exploration_steps in enumerate([2000, 3000, 4000, 5000, 6000, 7000]):\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    df_subset = df_agg.xs(exploration_steps, level='exploration_steps')\n",
    "    cycles = df_subset.index.get_level_values('cycle')\n",
    "    lppd_means = df_subset['lppd']['mean']\n",
    "    lppd_stds = df_subset['lppd']['std']\n",
    "\n",
    "    ax.errorbar(cycles, lppd_means, yerr=lppd_stds, fmt='o', color='red', markersize=2)\n",
    "    \n",
    "    ax.set_title(f'{exploration_steps//1000}k steps')\n",
    "    ax.set_xlabel('Cycle Index')\n",
    "    ax.set_xticks([2, 4, 6, 8, 10, 12])\n",
    "\n",
    "axs[0,0].set_ylabel('LPPD')\n",
    "axs[1,0].set_ylabel('LPPD')\n",
    "fig.tight_layout()\n",
    "# fig.savefig('../ba/images/ablation_cycle_length.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e9e06",
   "metadata": {},
   "source": [
    "### Cosine schedule (only parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe114805",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = [2, 4, 6, 8]\n",
    "seeds = [0, 42, 1973, 2025, 2100]\n",
    "res_parallel_cos = load_results('results/cosine', 'parallel', ms=ms, seeds=seeds, exploration_steps=11500, schedule='cosine')\n",
    "res_parallel_cos_combined = combine_mean_std(res_parallel_cos)\n",
    "res_parallel_cos_combined.rename(columns={\n",
    "    'm_': r'$M$',\n",
    "    'lppd': r'LPPD ($\\uparrow$)',\n",
    "    'rmse': r'RMSE ($\\downarrow$)'\n",
    "}, inplace=True)\n",
    "res_parallel_cos_combined.to_latex(\n",
    "    'tmp_cosine.tex',\n",
    "    index=False,\n",
    "    column_format='c' * len(res_parallel_cos_combined.columns),\n",
    "    escape=False,\n",
    "    multicolumn=True,\n",
    "    multicolumn_format='c',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
