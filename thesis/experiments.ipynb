{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b0c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bszh/MILE/venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bszh/MILE\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import functools\n",
    "from src.config.core import Config\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a5339",
   "metadata": {},
   "source": [
    "### Config template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915b8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DICT = {\n",
    "    'saving_dir': 'results/',\n",
    "    'experiment_name': 'bike',\n",
    "    'data': {\n",
    "        'path': 'data/bikesharing.data',\n",
    "        'source': 'local',\n",
    "        'data_type': 'tabular',\n",
    "        'task': 'regr',\n",
    "        'target_column': None,\n",
    "        'target_len': 1,\n",
    "        'features': None,\n",
    "        'datapoint_limit': None,\n",
    "        'normalize': True,\n",
    "        'train_split': 0.8,\n",
    "        'valid_split': 0.0,\n",
    "        'test_split': 0.2,\n",
    "    },\n",
    "    'model': {\n",
    "        'model': 'FCN',\n",
    "        'hidden_structure': [16, 16, 16, 2],\n",
    "        'activation': 'relu',\n",
    "        'use_bias': True,\n",
    "    },\n",
    "    'training': {\n",
    "        'warmstart': { # meaningless placeholder\n",
    "            'include': False,\n",
    "            'optimizer_config': {'name': \"sgd\", 'parameters': {}}\n",
    "        },\n",
    "        'sampler': {\n",
    "            'name': 'sgld',\n",
    "            'warmup_steps': 0,\n",
    "            'n_chains': 4,\n",
    "            'n_samples': 24000,  # total steps\n",
    "            'batch_size': 512,\n",
    "            'step_size_init': 2.0e-6,  # step_size_explore\n",
    "            'n_thinning': 1,\n",
    "            'keep_warmup': False,\n",
    "            'optimizer_name': 'sgd',\n",
    "            'prior_config': {\n",
    "                'name': 'StandardNormal'\n",
    "            },\n",
    "            'scheduler_config': {\n",
    "                'name': 'cosine',\n",
    "                'n_samples_per_cycle': 200,\n",
    "                'parameters': {\n",
    "                    'n_cycles': 4,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'rng': 1446,\n",
    "    'logging': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1615637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(\n",
    "        exp_name: str = 'bike',\n",
    "        n_chains: int = 4,\n",
    "        n_cycles: int = 4,\n",
    "        n_steps_per_cycle: int = 2000,\n",
    "        n_samples_per_cycle: int = 200,\n",
    "        n_thinning: int = 1,\n",
    "        optimizer_name: str = 'adam',\n",
    "        scheduler_name: str = 'cosine',\n",
    "        step_size_init: float = 2.0e-6,\n",
    "        step_size_sampling: float | None = None,\n",
    "        seed: int = 0\n",
    "    ):\n",
    "    n_samples = n_cycles * n_steps_per_cycle\n",
    "\n",
    "    new_config_dict = CONFIG_DICT.copy()\n",
    "    new_config_dict['experiment_name'] = exp_name\n",
    "    new_config_dict['training']['sampler'] = {\n",
    "        'name': 'sgld',\n",
    "        'warmup_steps': 0,\n",
    "        'keep_warmup': False,\n",
    "        'n_chains': n_chains,\n",
    "        'n_samples': n_samples,  # total steps\n",
    "        'batch_size': 512,\n",
    "        'step_size_init': step_size_init,  # step_size_explore\n",
    "        'n_thinning': n_thinning,\n",
    "        'optimizer_name': optimizer_name,\n",
    "        'prior_config': {\n",
    "            'name': 'StandardNormal'\n",
    "        },\n",
    "        'scheduler_config': {\n",
    "            'name': scheduler_name,\n",
    "            'n_samples_per_cycle': n_samples_per_cycle,\n",
    "            'parameters': {\n",
    "                'n_cycles': n_cycles,\n",
    "                'step_size_sampling': step_size_sampling\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    new_config_dict['rng'] = seed\n",
    "    new_config_dict['saving_dir'] = f'results/'\n",
    "    config_path = Path('experiments/csgld') / f'{exp_name}.yaml'\n",
    "    # if config_path.exists():\n",
    "    #     warnings.warn(f\"Config file {config_path} already exists. Overwriting it.\")\n",
    "    if not config_path.parent.exists():\n",
    "        config_path.parent.mkdir(parents=True)\n",
    "    Config.from_dict(new_config_dict).to_yaml(config_path)\n",
    "\n",
    "    return config_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901222c",
   "metadata": {},
   "source": [
    "### Chains/Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1da2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_cycles = [2, 4, 6, 8, 10, 12]\n",
    "seeds = [0, 42, 221, 476, 1453, 1644, 1840, 1973, 2025, 2100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5cdb79",
   "metadata": {},
   "source": [
    "### Constant Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c754be",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_config_constant = functools.partial(\n",
    "    get_config,\n",
    "    n_steps_per_cycle=5500,\n",
    "    n_samples_per_cycle=500,\n",
    "    n_thinning=10,\n",
    "    optimizer_name='adam',\n",
    "    scheduler_name='constant',\n",
    "    step_size_init=0.01,\n",
    "    step_size_sampling=1.0e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3bbc69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Running training for config: experiments/csgld/constant/2x1_constant_5000+500_seed0.yaml\n",
      "2025-07-13 14:43:34,166 - __main__ - INFO - Loaded 1 Experiment(s)\n",
      "2025-07-13 14:43:34,707 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-07-13 14:43:34,708 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-07-13 14:43:35,091 - __main__ - INFO - > Running experiment: constant/2x1_constant_5000+500_seed0\n",
      "2025-07-13 14:43:35,101 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-07-13 14:43:35,101 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-07-13 14:43:35,101 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-07-13 14:43:35,101 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2025-07-13 14:43:35,149 - src.training.trainer - INFO - > Setting up directories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling:  47%|████▋     | 2593/5500 [00:07<00:08, 332.20it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bszh/MILE/train.py\", line 133, in <module>\n",
      "    train_bde(cfg, n_devices)\n",
      "  File \"/home/bszh/MILE/train.py\", line 19, in train_bde\n",
      "    trainer.train_bde()\n",
      "  File \"/home/bszh/MILE/src/training/trainer.py\", line 177, in train_bde\n",
      "    self.start_sampling()\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/src/training/trainer.py\", line 598, in start_sampling\n",
      "    inference_loop_batch(\n",
      "  File \"/home/bszh/MILE/src/training/sampling_batch.py\", line 205, in inference_loop_batch\n",
      "    step_size = schedule_fn(step_count)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/src/training/sampling_batch.py\", line 192, in <lambda>\n",
      "    schedule_fn = lambda x: replicate(_scheduler_fn(x))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/flax/jax_utils.py\", line 45, in replicate\n",
      "    return jax.device_put_replicated(tree, devices)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/jax/_src/api.py\", line 2621, in device_put_replicated\n",
      "    return tree_map(_device_put_replicated, x)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/jax/_src/tree_util.py\", line 320, in tree_map\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/jax/_src/tree_util.py\", line 320, in <genexpr>\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "                             ^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/jax/_src/api.py\", line 2613, in _device_put_replicated\n",
      "    buf = device_put(x, devices[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/jax/_src/api.py\", line 2472, in device_put\n",
      "    return tree_map(_map, x)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/jax/_src/tree_util.py\", line 320, in tree_map\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bszh/MILE/venv/lib/python3.12/site-packages/jax/_src/tree_util.py\", line 320, in <genexpr>\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "  \n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning training for config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m12\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:1201\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:1264\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:2053\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 2053\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.12/subprocess.py:2011\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2011\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2012\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   2013\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   2016\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parallel\n",
    "config_paths_p = []\n",
    "for i, n in enumerate(chains_cycles):\n",
    "    for seed in seeds:\n",
    "        exp_name = f'constant/{n}x1_constant_5000+500_seed{seed+i}'\n",
    "        config_path = get_config_constant(\n",
    "            exp_name=exp_name,\n",
    "            n_chains=n,\n",
    "            n_cycles=1,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        config_paths_p.append(config_path)\n",
    "        result_path = Path('results') / exp_name / \"eval_metrics.pkl\"\n",
    "        if result_path.exists():\n",
    "            continue\n",
    "        print(\"=\" * 50)\n",
    "        print(f'Running training for config: {config_path}')\n",
    "        subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "config_paths_c = []\n",
    "max_cycles = int(np.max(chains_cycles))\n",
    "for i, n in enumerate(chains_cycles):\n",
    "    for seed in seeds:\n",
    "        exp_name = f'constant/1x{n}_constant_5000+500_seed{seed+i}'\n",
    "        config_path = get_config_constant(\n",
    "            exp_name=exp_name,\n",
    "            n_chains=1,\n",
    "            n_cycles=n,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        result_path = Path('results') / exp_name / \"eval_metrics.pkl\"\n",
    "        if result_path.exists():\n",
    "            continue\n",
    "        # print(config_path)\n",
    "        print(\"=\" * 50)\n",
    "        print(f'Running training for config: {config_path}')\n",
    "        subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel_configs = [(2, 6), (3, 4), (4, 3), (6, 2)]\n",
    "# for i, (n_chains, n_cycles) in enumerate(parallel_configs):\n",
    "#     for seed in seeds:\n",
    "#         exp_name = f'bike8/{n_chains}x{n_cycles}_constant_{5000}+{500}_10_seed{seed+i}'\n",
    "#         config_path = get_config_constant(\n",
    "#             exp_name=exp_name,\n",
    "#             n_chains=n_chains,\n",
    "#             n_cycles=n_cycles,\n",
    "#             seed=seed+i\n",
    "#         )\n",
    "#         result_path = Path('results') / exp_name / \"eval_metrics.pkl\"\n",
    "#         if result_path.exists():\n",
    "#             continue\n",
    "#         print(\"=\" * 50)\n",
    "#         print(f'Running training for config: {config_path}')\n",
    "#         subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c88c1c",
   "metadata": {},
   "source": [
    "### Cyclical Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_config_cyclical = functools.partial(\n",
    "    get_config,\n",
    "    n_steps_per_cycle=12000,\n",
    "    n_samples_per_cycle=500,\n",
    "    n_thinning=10,\n",
    "    optimizer_name='sgd',\n",
    "    scheduler_name='cosine',\n",
    "    step_size_init=2.0e-6\n",
    ")\n",
    "\n",
    "cosine_chains_cycles = [2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel\n",
    "for i, n in enumerate(cosine_chains_cycles):\n",
    "    for seed in seeds:\n",
    "        exp_name = f'cosine/{n}x1_cosine_5000+500_seed{seed+i}'\n",
    "        config_path = get_config_cyclical(\n",
    "            exp_name=exp_name,\n",
    "            n_chains=n,\n",
    "            n_cycles=1,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        result_path = Path('results') / exp_name / \"eval_metrics.pkl\"\n",
    "        if result_path.exists():\n",
    "            continue\n",
    "        print(\"=\" * 50)\n",
    "        print(f'Running training for config: {config_path}')\n",
    "        subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "for i, n in enumerate(cosine_chains_cycles):\n",
    "    for seed in seeds:\n",
    "        exp_name = f'cosine/1x{n}_cosine_5000+500_seed{seed+i}'\n",
    "        config_path = get_config_cyclical(\n",
    "            exp_name=exp_name,\n",
    "            n_chains=1,\n",
    "            n_cycles=n,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        result_path = Path('results') / exp_name / \"eval_metrics.pkl\"\n",
    "        if result_path.exists():\n",
    "            continue\n",
    "        print(\"=\" * 50)\n",
    "        print(f'Running training for config: {config_path}')\n",
    "        subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373fb8e",
   "metadata": {},
   "source": [
    "### Cycle Length Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_config_constant_different_length = functools.partial(\n",
    "    get_config,\n",
    "    n_thinning=10,\n",
    "    optimizer_name='adam',\n",
    "    scheduler_name='constant',\n",
    "    step_size_init=0.01,\n",
    "    step_size_sampling=1.0e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_steps = np.arange(2000, 8001, 1000)\n",
    "sampling_steps = 500\n",
    "for i, n in enumerate(exploration_steps):\n",
    "    for seed in seeds:\n",
    "        exp_name = f'exploration_budget/1x12_constant_{n}+{sampling_steps}_seed{seed+i}'\n",
    "        config_path = get_config_constant_different_length(\n",
    "            exp_name=exp_name,\n",
    "            n_chains=1,\n",
    "            n_cycles=12,\n",
    "            n_steps_per_cycle=int(n+sampling_steps),\n",
    "            n_samples_per_cycle=sampling_steps,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        result_path = Path('results') / exp_name / \"eval_metrics.pkl\"\n",
    "        if result_path.exists():\n",
    "            continue\n",
    "        print(\"=\" * 50)\n",
    "        print(f'Running training for config: {config_path}')\n",
    "        subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration_steps = np.arange(2000, 8001, 1000)\n",
    "# # seeds = [476, 1453, 1644, 1806, 1912]\n",
    "# sampling_steps = 500\n",
    "# for i, n in enumerate(exploration_steps):\n",
    "#     # if n != 5000:\n",
    "#     #     continue\n",
    "#     for seed in seeds:\n",
    "#         exp_name = f'bike10/8x1_constant_{n}+{sampling_steps}_10_seed{seed+i}'\n",
    "#         config_path = get_config_constant_different_length(\n",
    "#             exp_name=exp_name,\n",
    "#             n_chains=12,\n",
    "#             n_cycles=1,\n",
    "#             n_steps_per_cycle=int(n),\n",
    "#             n_samples_per_cycle=sampling_steps,\n",
    "#             seed=seed+i\n",
    "#         )\n",
    "#         result_path = Path('results') / exp_name / \"eval_metrics.pkl\"\n",
    "#         if result_path.exists():\n",
    "#             continue\n",
    "#         print(\"=\" * 50)\n",
    "#         print(f'Running training for config: {config_path}')\n",
    "#         subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
