{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b0c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-18 12:08:50,196 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-06-18 12:08:50,198 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-06-18 12:08:50,640 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-06-18 12:08:50,641 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-06-18 12:08:50,642 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-06-18 12:08:50,643 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import warnings\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from src.config.core import Config\n",
    "from src.config.sampler import Sampler\n",
    "from src.config.data import DatasetType\n",
    "import src.dataset as ds\n",
    "from src.models.tabular import FCN\n",
    "import src.training.utils as train_utils\n",
    "import src.inference.utils as inf_utils\n",
    "import src.visualization as viz\n",
    "from src.config.data import Task\n",
    "from src.inference.evaluation import evaluate_bde\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a5339",
   "metadata": {},
   "source": [
    "### Config template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915b8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DICT = {\n",
    "    'saving_dir': 'results/',\n",
    "    'experiment_name': 'bike',\n",
    "    'data': {\n",
    "        'path': 'data/bikesharing.data',\n",
    "        'source': 'local',\n",
    "        'data_type': 'tabular',\n",
    "        'task': 'regr',\n",
    "        'target_column': None,\n",
    "        'target_len': 1,\n",
    "        'features': None,\n",
    "        'datapoint_limit': None,\n",
    "        'normalize': True,\n",
    "        'train_split': 0.7,\n",
    "        'valid_split': 0.1,\n",
    "        'test_split': 0.2,\n",
    "    },\n",
    "    'model': {\n",
    "        'model': 'FCN',\n",
    "        'hidden_structure': [16, 16, 16, 2],\n",
    "        'activation': 'relu',\n",
    "        'use_bias': True,\n",
    "    },\n",
    "    'training': {\n",
    "        'warmstart': { # meaningless placeholder\n",
    "            'include': False,\n",
    "            'optimizer_config': {'name': \"sgd\", 'parameters': {}}\n",
    "        },\n",
    "        'sampler': {\n",
    "            'name': 'sgld',\n",
    "            'warmup_steps': 0,\n",
    "            'n_chains': 4,\n",
    "            'n_samples': 24000,  # total steps\n",
    "            'batch_size': 512,\n",
    "            'step_size_init': 2.0e-6,  # step_size_explore\n",
    "            'n_thinning': 1,\n",
    "            'keep_warmup': False,\n",
    "            'optimizer_name': 'sgd',\n",
    "            'prior_config': {\n",
    "                'name': 'StandardNormal'\n",
    "            },\n",
    "            'scheduler_config': {\n",
    "                'name': 'Cyclical',\n",
    "                'n_samples_per_cycle': 200,\n",
    "                'parameters': {\n",
    "                    'n_cycles': 4,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'rng': 1446,\n",
    "    'logging': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1615637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(\n",
    "        exp_name: str = 'bike',\n",
    "        n_chains: int = 4,\n",
    "        n_cycles: int = 4,\n",
    "        n_steps_per_cycle: int = 2000,\n",
    "        n_samples_per_cycle: int = 200,\n",
    "        n_thinning: int = 1,\n",
    "        optimizer_name: str = 'adam',\n",
    "        scheduler_name: str = 'Cyclical',\n",
    "        step_size_init: float = 2.0e-6,\n",
    "        step_size_sampling: float | None = None,\n",
    "        seed: int = 0\n",
    "    ):\n",
    "    n_samples = n_cycles * n_steps_per_cycle\n",
    "\n",
    "    new_config_dict = CONFIG_DICT.copy()\n",
    "    new_config_dict['experiment_name'] = exp_name\n",
    "    new_config_dict['training']['sampler'] = {\n",
    "        'name': 'sgld',\n",
    "        'warmup_steps': 0,\n",
    "        'keep_warmup': False,\n",
    "        'n_chains': n_chains,\n",
    "        'n_samples': n_samples,  # total steps\n",
    "        'batch_size': 512,\n",
    "        'step_size_init': step_size_init,  # step_size_explore\n",
    "        'n_thinning': n_thinning,\n",
    "        'optimizer_name': optimizer_name,\n",
    "        'prior_config': {\n",
    "            'name': 'StandardNormal'\n",
    "        },\n",
    "        'scheduler_config': {\n",
    "            'name': scheduler_name,\n",
    "            'n_samples_per_cycle': n_samples_per_cycle,\n",
    "            'parameters': {\n",
    "                'n_cycles': n_cycles,\n",
    "                'step_size_sampling': step_size_sampling\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    new_config_dict['rng'] = seed\n",
    "\n",
    "    # datetime_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    new_config_dict['saving_dir'] = f'results/'\n",
    "    config_path = Path('experiments/csgld') / f'{exp_name}.yaml'\n",
    "    # if config_path.exists():\n",
    "    #     warnings.warn(f\"Config file {config_path} already exists. Overwriting it.\")\n",
    "    if not config_path.parent.exists():\n",
    "        config_path.parent.mkdir(parents=True)\n",
    "    Config.from_dict(new_config_dict).to_yaml(config_path)\n",
    "\n",
    "    return config_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901222c",
   "metadata": {},
   "source": [
    "### Chains/Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1da2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_cycles = [2, 4, 6, 8, 10, 12]\n",
    "seeds = [i for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5cdb79",
   "metadata": {},
   "source": [
    "### Constant Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c754be",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_config_constant = functools.partial(\n",
    "    get_config,\n",
    "    n_steps_per_cycle=2500,\n",
    "    n_samples_per_cycle=500,\n",
    "    n_thinning=1,\n",
    "    optimizer_name='adam',\n",
    "    scheduler_name='Constant',\n",
    "    step_size_init=0.01,\n",
    "    step_size_sampling=1.0e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec524b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.disable(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3bbc69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Running training for config: experiments/csgld/bike2/parallel_constant_12_seed0.yaml\n",
      "2025-06-18 12:08:55,847 - __main__ - INFO - Loaded 1 Experiment(s)\n",
      "2025-06-18 12:08:56,392 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-06-18 12:08:56,392 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-06-18 12:08:56,880 - __main__ - INFO - > Running experiment: bike2/parallel_constant_12_seed0\n",
      "2025-06-18 12:08:56,890 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-06-18 12:08:56,890 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-06-18 12:08:56,890 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-06-18 12:08:56,891 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2025-06-18 12:08:56,935 - src.training.trainer - INFO - > Setting up directories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 2500/2500 [00:17<00:00, 140.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Running training for config: experiments/csgld/bike2/parallel_constant_12_seed1.yaml\n",
      "2025-06-18 12:10:40,627 - __main__ - INFO - Loaded 1 Experiment(s)\n",
      "2025-06-18 12:10:41,206 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-06-18 12:10:41,207 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-06-18 12:10:41,591 - __main__ - INFO - > Running experiment: bike2/parallel_constant_12_seed1\n",
      "2025-06-18 12:10:41,600 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-06-18 12:10:41,600 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-06-18 12:10:41,601 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-06-18 12:10:41,602 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2025-06-18 12:10:41,647 - src.training.trainer - INFO - > Setting up directories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 2500/2500 [00:17<00:00, 142.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Running training for config: experiments/csgld/bike2/parallel_constant_12_seed2.yaml\n",
      "2025-06-18 12:12:24,636 - __main__ - INFO - Loaded 1 Experiment(s)\n",
      "2025-06-18 12:12:25,208 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-06-18 12:12:25,209 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-06-18 12:12:25,592 - __main__ - INFO - > Running experiment: bike2/parallel_constant_12_seed2\n",
      "2025-06-18 12:12:25,602 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-06-18 12:12:25,602 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-06-18 12:12:25,602 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-06-18 12:12:25,602 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2025-06-18 12:12:25,643 - src.training.trainer - INFO - > Setting up directories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 2500/2500 [00:16<00:00, 148.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Running training for config: experiments/csgld/bike2/parallel_constant_12_seed3.yaml\n",
      "2025-06-18 12:14:06,983 - __main__ - INFO - Loaded 1 Experiment(s)\n",
      "2025-06-18 12:14:07,517 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-06-18 12:14:07,518 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-06-18 12:14:07,891 - __main__ - INFO - > Running experiment: bike2/parallel_constant_12_seed3\n",
      "2025-06-18 12:14:07,900 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-06-18 12:14:07,900 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-06-18 12:14:07,901 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-06-18 12:14:07,901 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2025-06-18 12:14:07,945 - src.training.trainer - INFO - > Setting up directories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 2500/2500 [00:17<00:00, 143.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Running training for config: experiments/csgld/bike2/parallel_constant_12_seed4.yaml\n",
      "2025-06-18 12:15:50,713 - __main__ - INFO - Loaded 1 Experiment(s)\n",
      "2025-06-18 12:15:51,250 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-06-18 12:15:51,251 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-06-18 12:15:51,627 - __main__ - INFO - > Running experiment: bike2/parallel_constant_12_seed4\n",
      "2025-06-18 12:15:51,636 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-06-18 12:15:51,636 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-06-18 12:15:51,637 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-06-18 12:15:51,637 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2025-06-18 12:15:51,680 - src.training.trainer - INFO - > Setting up directories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 2500/2500 [00:43<00:00, 57.84it/s] \n"
     ]
    }
   ],
   "source": [
    "# parallel\n",
    "config_paths_p = []\n",
    "for i, n in enumerate(chains_cycles):\n",
    "    if n != 12:\n",
    "        continue\n",
    "    for seed in seeds:\n",
    "        exp_name = f'bike2/parallel_constant_{n}_seed{seed}'\n",
    "        config_path = get_config_constant(\n",
    "            exp_name=exp_name,\n",
    "            n_chains=n,\n",
    "            n_cycles=1,\n",
    "            seed=seed+i\n",
    "        )\n",
    "        config_paths_p.append(config_path)\n",
    "\n",
    "for config_path in config_paths_p:\n",
    "    print(\"=\" * 50)\n",
    "    print(f'Running training for config: {config_path}')\n",
    "    subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "config_paths_c = []\n",
    "max_cycles = int(np.max(chains_cycles))\n",
    "for seed in seeds:\n",
    "    exp_name = f'bike/sequential_constant_{max_cycles}_seed{seed}'\n",
    "    config_path = get_config_constant(\n",
    "        exp_name=exp_name,\n",
    "        n_chains=10,\n",
    "        n_cycles=max_cycles,\n",
    "        seed=seed\n",
    "    )\n",
    "    # print(f'Config saved to {config_path}')\n",
    "    config_paths_c.append(config_path)\n",
    "\n",
    "for config_path in config_paths_c:\n",
    "    print(\"=\" * 50)\n",
    "    print(f'Running training for config: {config_path}')\n",
    "    subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5053ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-18 10:55:25,631 - __main__ - INFO - Loaded 1 Experiment(s)\n",
      "2025-06-18 10:55:26,462 - datasets - INFO - PyTorch version 2.2.2+cpu available.\n",
      "2025-06-18 10:55:26,463 - datasets - INFO - JAX version 0.4.28 available.\n",
      "2025-06-18 10:55:27,064 - __main__ - INFO - > Running experiment: bike/sequential_constant_4_seed3\n",
      "2025-06-18 10:55:27,074 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': \n",
      "2025-06-18 10:55:27,074 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-06-18 10:55:27,075 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-06-18 10:55:27,075 - jax._src.xla_bridge - WARNING - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2025-06-18 10:55:27,128 - src.training.trainer - INFO - > Setting up directories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 10000/10000 [00:28<00:00, 347.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'train.py', '-c', 'experiments/csgld/bike/sequential_constant_4_seed3.yaml', '-d', '12'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = 'bike/sequential_constant_4_seed3'\n",
    "config_path = get_config_constant(\n",
    "    exp_name=exp_name,\n",
    "    n_chains=1,\n",
    "    n_cycles=4,\n",
    "    seed=3\n",
    ")\n",
    "subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c88c1c",
   "metadata": {},
   "source": [
    "### Cyclical Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_config_cyclical = functools.partial(\n",
    "    get_config,\n",
    "    n_steps_per_cycle=6000,\n",
    "    n_samples_per_cycle=200,\n",
    "    n_thinning=1,\n",
    "    optimizer_name='sgd',\n",
    "    scheduler_name='Cyclical',\n",
    "    step_size_init=2.0e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel\n",
    "config_paths_p = []\n",
    "for i, n in enumerate(chains_cycles):\n",
    "    for seed in seeds:\n",
    "        exp_name = f'bike/parallel_cyclical_{n}_seed{seed}'\n",
    "        config_path = get_config_cyclical(\n",
    "            exp_name=exp_name,\n",
    "            n_chains=n,\n",
    "            n_cycles=1,\n",
    "            seed=seed\n",
    "        )\n",
    "        config_paths_p.append(config_path)\n",
    "\n",
    "for config_path in config_paths_p:\n",
    "    print(\"=\" * 50)\n",
    "    print(f'Running training for config: {config_path}')\n",
    "    subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "config_paths_s = []\n",
    "max_cycles = int(np.max(chains_cycles))\n",
    "# for seed in seeds:\n",
    "exp_name = f'bike/sequential_cyclical_{max_cycles}_combined'\n",
    "config_path = get_config_cyclical(\n",
    "    exp_name=exp_name,\n",
    "    n_chains=len(seeds),\n",
    "    n_cycles=max_cycles,\n",
    "    seed=0\n",
    ")\n",
    "config_paths_s.append(config_path)\n",
    "\n",
    "for config_path in config_paths_s:\n",
    "    print(\"=\" * 50)\n",
    "    print(f'Running training for config: {config_path}')\n",
    "    subprocess.run(['python', 'train.py', '-c', str(config_path), '-d', '12'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
